\chapter{Weryfikacja obiektowo-kodowa}

Ocenę metod weryfikacji odcisków należy wystawić przede wszystkim na podstawie ilości błędów popełnianych przez obie metody. W takim przypadku metody obiektowe zostawiają daleko w tyle opisywaną metodę kodową. Błędy EER w granicach 16\% -20\% świadczą o dużej zawodności metody. W książce  \emph{Handbook of fingerprint recognition} \cite{finger_book} prezentowana jest tabela prezentująca błędy EER dla znanych algorytmów porównywania odcisków. W czołówce znajdują się algorytmy o EER poniżej 1\%, a najlepszy przedstawiany algorytm (PA15) ma skuteczność na poziomie 0.19\%. Tabele zamykają algorytmy o skuteczności 12\%- 16\%, 23\% i 50\%. Oznacza to, że moje rozwiązanie mogłoby być porównywane z niektórymi najsłabszymi algorytmami przedstawianymi w książce. Najgorsze komercyjne rozwiązanie ma skuteczność 12.09\% co oznacza, że mój algorytm jest niewiele gorszy. Dodatkowo w przypadku prób zapewnienia zerowych błędów fałszywej akceptacji lub fałszywego odrzucenia algorytm staje się kompletnie bezużyteczny. Jednak metoda niekoniecznie musi zostać porzucona warto zauważyć, że algorytm kodujący nie korzysta z żadnych zaawansowanych metod. Jest to tylko wyłącznie proste kodowanie poprzez podzielenie przestrzeni na mniejsze fragmenty i stwierdzanie czy minucja znajduje się w niej czy też nie. Ciężko wyciągać wnioski bez przeprowadzenia eksperymentu, ale gdyby zamiast określać miejsca w którym znajduje się minucja określać gdzie znajduje się z pewnym prawdopodobieństwem to metoda kodowa mogłaby być skuteczniejsza. Jednak takie podejście nie mówi wprost o ilości dopasowanych minucji. I prawdopodobnie również byłoby nieskuteczne dowodzi tego test przeprowadzony w poprzednim rozdziale. Porównywano tam nie tylko bezpośrednio odpowiadające kratki kodu ale też i sąsiednie. W obecnym podejściu algorytm podejmuje binarne decyzje co do dopasowania minucji. Wersja z kodowaniem prawdopodobieństwa położenia minucji w danym obszarze stwierdza dopasowanie minucji wraz z prawdopodobieństwem. Reasumując niełatwe jest wtedy stwierdzenie ile minucji dopasowano a ile nie. Podejście takie utrudniałoby badanie podobieństwa i niepodobieństwa obrazów na podstawie liczby dopasowanych i niedopasowanych minucji, a właśnie takie założenie przyjmuje ta praca. Innym sposobem poprawy jest znalezienie sposobu na kompensacje nieliniowych odkształceń opuszka palca w procesie pobierania odcisku. W aktualnym rozwiązaniu stosowane są przekształcenia(obroty i przesunięcia) dla całego obrazu. Nie stosowane są lokalne transformacje obrazu. Nie jasny jest też sposób realizacji takich przekształceń. Możliwym problemem wprowadzenia tego pomysłu jest nieskończony zbiór przekształceń jaki można wykonać na obrazie. Mówiąc prościej i tak należałoby arbitralnie wybrać jakąś grupę przekształceń bez pewności, że wśród nich znajduje się przekształcenie kompensujące zniekształcenia w obrazie. Tak naprawdę bardzo trudno jest znaleźć dobre wyjście z tego problemu, bo nie wiadomo co jest poszukiwane. Dobrym kierunkiem rozwoju metody jest, wspomniane powyżej, kompletne odejście od liczby dopasowanych minucji. Algorytm stwierdzi jedynie ważone prawdopodobieństwo dopasowania obrazu. Rozwiązanie takie różni się od obecnego tym, że zniekształcenia obrazu są kompensowane nie tylko przez rozmiar kratki kodu ale również przez przynależność do sąsiednich kratek. Jest to jednak temat na kolejne badania.
\section [Ocena i porównanie metod][Ocena i porównanie metod]{Ocena i porównanie metod}
Kolejnym etapem pracy było stworzenie mechanizmu porównywania kodów. Rozważano kilka sposobów porównań.
\renewcommand*{\labelitemi}{\bullet}
\begin{itemize}
	\item porównywanie naiwnego kodu
	\item porównywanie macierzy kodów(transformacje na obrazie próbki)
	\begin{itemize}
		\item porównywanie podobieństwa
		\item porównywanie niepodobieństwa
		\item porównywanie podobieństwa i niepodobieństwa jednocześnie(3D)
	\end{itemize}
\end{itemize}
Dla algorytmu kodującego najskuteczniejsze okazało się porównywanie niepodobieństwa i transformacje obrazu próbki. Dla liczby minucji dopasowanych i niedopasowanych pozyskiwanych od SDK $Neurotechnology$ najskuteczniejszą metodą okazała się metoda 3D porównywania kodów. Skuteczność takiego porównania daje wynik w granicach 0.5\% błędnych decyzji. Wynik ten śmiało mógłby rywalizować z przedstawianym algorytmami w książce $Handbook of fingerprint recognition$\cite{finger_book}. Niestety nie jest to moje autorskie rozwiązanie a jedynie wykorzystanie komercyjnego SDK w połączeniu z moją metodą. Wynik jednak jest bardzo dobry i taki system mógłby być działającym powszechnie systemem biometrycznym. Konieczne jest jedynie nauczenie klasyfikatora SVM odpowiedniej funkcji separującej. W opisywanej pracy funkcje zostały otrzymane na niezbyt dużych bazach danych. Zwiększenie zbioru uczącego przyczyni się do większego generalizowania zachowania rozkładu ilości punktów dopasowanych i niedopasowanych minucji. Metoda ta nie jest uniwersalna, oznacza to ze proces uczenia klasyfikatora powinien być dostosowywany do oprogramowania, które oblicza liczby dopasowanych i niedopasowanych cech. Jak każda metoda tak i ta posiada wady. Ten sposób klasyfikacji nie daje oczekiwanych rezultatów gdy zbiór punktów dopasowania i zbiór punktów niedopasowania nie jest rozłączny. W przypadku przedstawianego algorytmu kodującego metoda te prowadzi wręcz do pogorszenia wyników. 

